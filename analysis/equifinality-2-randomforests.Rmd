---
title: "Model Selection By Classification:  Equifinality-2-Small"
author: "Mark E. Madsen"
date: "September 26, 2014"
output: 
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 2
    latex_engine: xelatex
    keep_tex: true
mainfont: Minion Pro
monofont: Bitstream Vera Sans Mono
mathfont: Minion Math
sansfont: ITC Legacy Sans Std Medium
fontsize: 11pt
bibliography: ../paper/madsen2015-ctmixtures.bib
csl-style: american-antiquity.csl
---

```{r, echo=FALSE, results='asis', warning=FALSE, message=FALSE}
source('randomforest-functions.R')
# load data frame, results in object "eq2_pop_df" in the workspace
load("~/local-research/diss/experiments/experiment-ctmixtures/equifinality-2-small-population-data.rda")  
```

# Purpose #



Equifinality-2-small is a classification experiment, attempting to distinguish models using summary statistics on 1000 samples from each of four models with random prior parameters:

1.  Population with pure neutral copying
1.  Equal mix of conformists and anti-conformists, with random bias strengths
1.  Mixture of conformists and anti-conformists, conformists dominating, with random bias strengths
1.  Mixture of conformists and anti-conformists, anticonformists dominating, with random bias strengths

This experiment has the same prior configuration as `equifinality-1`, which I threw out until I could verify and fix a small issue with mutation rates being exactly correct and verifiable.  In all cases, the copying algorithms here use single-locus copying during a copying event, over 4 loci.  Thus, the amount of variation in the neutral model case is **not** precisely what one expects from a Moran model given Ewens [-@Ewens2004].  

The goal of this analysis is to work through the following data sets, examining when and how equifinality manifests in distinguishing empirical statistics from samples or the entire population:

1.  Population census data, synchronic and one diachronic summary statistic
1.  Sample data, synchronic and one diachronic summary statistic
1.  Time averaged and sampled data, time averaged and diachronic time averaged summary statistics

The "raw" summary statistics available for analysis are as follows:

1.  Trait and configuration (product space of traits) richness
1.  Slatkin exact tests on traits and configurations
1.  Shannon entropy of trait and configuration frequencies
1.  IQV evenness of trait and configuration frequencies
1.  Kandler-Shennan trait survival over fixed interval

# Methods #

Lorem ipsum


# Population Census Statistics #

## Four-Model Analysis, All Variables ##

```{r four-model-forest, results='asis', echo=FALSE}
excluded_fields = c("simulation_run_id", "innovation_rate")

# run random forest with default metaparameters against the "model_class_label" field
four_full_model <- do_random_forest(eq2_pop_df, "model_class_label", excluded_fields)

test_error <- four_full_model["prediction_rate"]
four_fit <- four_full_model["fit"]

```

All variables (except non-statistics like the innovation rate, which is a simulation parameter, and the simulation run ID) are included in this initial analysis.  With the full set of four models, The prediction rate on novel data is `r test_error`. The confusion matrix from the fit on training data is:

```{r four-model-test, echo=FALSE}
print(four_fit$fit["confusion"])
```

This confusion matrix indicates a couple of important points:

1.  With population census data, synchronic samples of multiple summary statistics, and one diachronic summary statistic, it is easy to distinguish between neutral populations and all of the populations generated by biased transmission models.  The classification error for "allneutral" versus any of the other models seems to be very low.  
1.  It is very difficult to differentiate biased models from each other given these summary statistics.  

## Two-Model Analysis, Full Data ##

```{r two-model, echo=FALSE, results='asis'}
# create a label combining the biased models into one
eq2_pop_df$two_class_label <- factor(ifelse(eq2_pop_df$model_class_label == 'allneutral', 'neutral', 'biased'))

# exclude the original four class labels from the random forest classifier
excluded_fields <- c("simulation_run_id", "model_class_label", "innovation_rate")
two_model <- do_random_forest(eq2_pop_df, "two_class_label", excluded_fields)

two_fit <- two_model["fit"]
test_error <- two_model["prediction_rate"]
test_table <- two_model["test_confusion"]

```

Point 1, the ability to distinguish neutral and biased populations from census data and synchronic/diachronic summary statistics, is demonstrated most clearly by collapsing biased models into a single class, and looking at classification rates simply between "neutral" and "biased" labels.  Doing so, with the same random forest setup, yields a `r test_error` prediction rate on novel test data, and the following confusion matrix from the original fit on the training data:

```{r two-confusion, echo=FALSE}
print(two_fit$fit["confusion"])
```

## Summary Statistic Selection ##

Lorem ipsum




# References Cited #



