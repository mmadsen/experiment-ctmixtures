
```{r libraries, echo=FALSE, cache=FALSE} 
library(ggplot2) 
library(xtable) 
library(dplyr)
library(magrittr)
library(mmadsenr)
options(tikzDefaultEngine = "xetex")


data_directory <- "/Users/mark/local-research/diss/experiments"

```

# Introduction

A major use of cultural transmission models in archaeology over the past decade has been inference regarding the type of social learning process (or "mode of transmission") operative within past populations.  Identifying the mode of past cultural transmission is important, for example, to testing evolutionary hypotheses for how cumulative cultural transmission and complex culture evolved in the first place [e.g., @BR1985; @CF1981; @Henrich:1998ek; @Wakano:2007gq].  In more recent archaeological settings, the identification of frequency-biased social learning is often linked to the sociopolitical structure of past societies [e.g., @kohler2004].  In fact, a great deal of the theoretical work on cultural transmission within archaeology during the first decade of the twenty-first century focused upon understanding the statistical "signatures" of different modes of transmission and how one might infer such modes from archaeological data [e.g, @Bentley2003; @bentley2007regular; @bentley2004random; @kohler2004; @Mesoudi2009; @shennan2001ceramic; @steele2010ceramic].  The degree to which such inferences are successful, however, remains an open question.    

One of the principal lessons of more recent work is that social learning modes which can be easily distinguished in simple models, become less distinguishable in models which incorporate more complex structure and realism, as work on variable population size and time averaging reveals [@Madsen2012TA; @Porcic2014Exploring-the-E; @Premo:2014jv; @Rorabaugh:2014fl]   At the extreme, models can be "equifinal," leading to the same patterns within data despite describing very different processes [@von1949problems].  In particular,  complex cultural transmission models which introduce one or more sources of heterogeneity within a population, will often display empirical patterns which overlap, despite arising from distinct underlying processes [@Mesoudi2009,p42].  Equifinality between theoretical models is a serious concern whenever we study complex systems, and has been discussed in geomorphology, hydrology, climatology, and within archaeology itself [@Aronica:1998dm; @Beven:2006js; @Bonham:2009bi; @Cicchetti:1996gp; @Culling:1987kx; @Marean:1992hg; @Rogers:2000bq; @Savenije:2001fe].  

When considerable equifinality exists between theoretical models, we cannot treat them as distinguishable in our data, despite the fact that we may be able to fit one of the models to our data with acceptable significance values or errors.  I argue that when we cannot distinguish models **up front** using analytical results or statistical analysis of simulation data, we should not treat them as competing hypotheses in an empirical study.  Where we can distinguish among a model set, however, we can proceeed with reasonable confidence to employ estimation and model selection techniques to infer which model has the best fit to a set of empirical data.   

The approach to equifinality assessment demonstrated here is to characterize the behavior of each candidate transmission model through Monte Carlo or agent-based simulation, and then examine our ability to predict the model which generated each data point using standard machine learning classifier systems, whose performance is known to approach optimal.  This approach provides powerful evidence of equifinality where it exists, even with cultural transmission models for which we lack analytical expressions.  Furthermore, we also gain useful information about which variables are effective at distinguishing between transmission models given the data.  In the case of failures to assign the correct model to a data point, the pattern of failures can help understand whether equifinality is potentially avoidable given changes to the data collection strategy.  I demonstrate the approach in the case of biased cultural transmission (in various mixtures), in comparison with the typical null hypothesis of neutral or unbiased copying.   

The results indicate that while neutral and biased transmission models can be distinguished very accurately given measurements from entire populations taken without temporal aggregation, the introduction of sampling and the interaction between sampling and temporal aggregation can markedly degrade our ability to distinguish between unbiased and biased transmission.  Furthermore, the degredation is not symmetric.  With sampled, time averaged data, we are extremely likely to conclude that samples represent biased transmission, even when this is not the case.  Reducing this equifinality may be possible given the ability to gather large samples, include variables not measured here, or reduce the duration over which samples are time averaged.  Where such reductions in equifinality are not possible and only coarse-grained data are available, investigators would be well advised to reformulate their research questions.  


# Theory #

Equifinality among theoretical models can arise from two sources.  First, there is strong overlap in the statistical outcomes of stochastic evolutionary models, given the large amount of variation in natural populations.  There may be combinations of parameter values, for example, where two processes yield outcomes which are strongly overlapping across any of the variables we can measure.  This is one of the reasons why Warren Ewens stopped working on neutrality tests for the infinite-alleles model after his seminal works of the 1970's \textemdash given the kind of data available at the level of alleles (rather than sequences), tests for distinguishing neutrality from selection models have little power [@plutinski2004].  I refer to this type of equifinality as __irreducible__.  Irreducibly equifinal  models form an __equivalence class__ of models that we cannot distinguish given our data.  Instead, all we can say is that our data could have been generated by any of the models in the equivalence class.  If only a few of the models we are studying are equifinal, and there are still distinctions which can be made, then we can simply reframe our analysis in terms of making distinctions between equivalence classes.  But when all of the models we consider fall into a single equivalence class, we are better off expanding the analysis and focusing upon a different model set or changing the scale of analysis. 

Second, equifinality may occur because of our measurement and analysis procedures.  There is growing evidence, for example, that time averaging affects our ability to distinguish biased from neutral transmission given most summary statistics (but possibly not all) [@Premo:2014jv], and that samples with smaller temporal duration suffer less from time averaging effects than deposits of long duration [@Madsen2012TA; @Porcic2014Exploring-the-E; @Premo:2014jv].  When equifinality arises because of the interaction between data collection techniques and theoretical models, it may be __reducible__ given different choices of variables and statistics or changing the resolution of data collection where possible.  It may also be the case that some models may be readily distinguished in experimental situations where we can observe transmission chains [e.g., @kempe2014experimental; @mesoudi2014experimental; @schillinger2014copying] but not in pure observational studies.  

In planning research aimed at selecting the best fitting model, we should answer two questions at the start of an analysis.  First, are the models statistically distinguishable, in the space of the variables measured?  To the extent that models are not, equifinality exists.  Second, is there evidence that equifinality is reducible in some manner (e.g., by employing additional predictors or finer-grained measurements)?  

The first question is answered by examining the overlap between the distributions of outcomes each model generates.  If there is no overlap, as in the left panel of Figure \ref{img:separability-example}, we may conclude that equifinality between the models is not an issue.  As the second and third panels show, however, increasing overlap makes it increasingly difficult to employ the values of predictor 1 and predictor 2 to predict which model produced a given data point.  Equifinality exists, to varying degrees, in both of these examples.   

\begin{figure}[ht]
\centering
\includegraphics[scale=0.3]{figure/distributional-overlap.pdf}
\caption{Simple example of model outcomes with separable distributions (A), two models with a limited overlap region (B), and two models whose outcomes are highly overlapping, and would cause equifinality in an analysis (C).}
\label{img:separability-example}
\end{figure}  


The problem of determining overlap involves probability densities which are often unknown or intractable.  Even for simple models, such as the neutral Wright-Fisher model which underlies most modeling of unbiased cultural transmission, we do not have an expression for the probability density of the model over commonly measured variables.  For example, we have no expression for the time to extinction for a trait (instead, we use values obtained through diffusion approximation) [@Ewens2004].  

We can, instead, formalize the problem of overlap as a problem of "classification" (in the sense of statistical learning rather than archaeological classification), where we determine how accurately we can predict the model from which a simulated data point was generated [@hastie2009elements].  The degree to which we cannot correctly predict the model associated with each data point represents the error of the classifier.  In the present context, the minimum possible error rate is a practical measure of equifinality.  

The lowest possible error is called the _Bayes error_, and represents the error rate achieved when each data point is given a class prediction corresponding to the maximum posterior probability across classes [@devijver1982pattern; @fukunaga1990introduction; @hastie2009elements].  Thus, the Bayes error is zero when we can correctly identify each data point as to its model of origin, and rises as two models overlap in the measurement space.  With sufficient overlap, the Bayes error could approach 0.5, which represents a prediction rule which is no better than chance.  This level of error represents full equifinality between models.\footnote{Predictors can achieve even worse error levels, performing more poorly than coin-flipping, but such rules do not help us assess equifinality.  Instead, such error rates in a predictive modeling context are an indication that the wrong modeling technique has been chosen.}  Unfortunately, we can almost never directly calculate the Bayes error rate for a prediction or classification rule, because again we lack the ability to simulate values from the posterior distribution.   Bayes error can be directly calculated, in fact, for a small number of cases, such as Gaussian distributions with a shared covariance matrix.\footnote{There is a large literature, especially in pattern recognition and language classification, on approximating upper bounds for the Bayes error of a classifier, because it is highly useful to know when you cannot improve a recognition system or classifier any further \citep{Antos:1999dn, Dobbin:2009du, McLachlan:1975eo}.  Most such upper bounds are based upon parametric models, and use estimates of a distance metric between the classes being distinguished (typically, the Mahalanobis or Bhattacharyya distance) \citep{devijver1982pattern}.  Such bounds are difficult to justify in situations where we have complex social learning models, whose probability density functions in the space of measured variables are typically unknown and are unlikely to be Gaussian.  Nonparametric bounds are possible, using nearest-neighbor methods \citep{Loizou:1987bi}, but in most cases the values obtained are not very tight and may not be useful.}  

Instead, Bayes error rates are in practice estimated empirically, by employing classification methods which are known to be good minimizers of test error.  In particular, ensemble approaches that combine many classifier rules are attractive since they achieve some of the best generalization error in prediction tests [@hastie2009elements], and thus come closest to estimating the Bayes rate [@tumer2003bayes].   This is the most practical approach for applications.  The general idea will be to simulate a large number of samples from each cultural transmission model whose equifinality we want to assess, train a predictive classifier model on a portion of those simulated samples until we find the smallest error (using cross-validation), and then use the performance of the classifier on the held-out portion of the simulated samples as an unbiased estimate of the true discrimination error between models.  Very low test error would indicate a clean ability to distinguish between models, and thus no equifinality.  As test error increases, the evidence for potential equifinality between models increases. 

The second question is answered by examining the pattern of classifier errors across measurement conditions.  For example, highly time averaged samples might yield more classification errors, and thus evidence of equifinality, than short duration samples.  Smaller samples of simulated data might be more difficult to correctly assign to their generating model than larger samples.  By simulating each of these measurement conditions on every sample of simulated data, the "onset" of equifinality can be assessed for different data collection strategies.  

# Materials and Methods #

In order to demonstrate the use of classifiers to assess equifinality, I consider four cultural transmission models:

1.  Neutral or unbiased cultural transmission
2.  Mixture of equal numbers of conformists and anti-conformists. 
3.  A mixture dominated by conformists, but with 30% anti-conformists.
4.  A mixture dominated by anti-conformists, but with 30% anti-conformists.  

This set of models was chosen because there should be strong potential for overlap in their observable consequences, when we compare their overlap in pairs or groups.  A population with no bias to common or uncommon traits might, when viewed in the aggregate, look much like a population composed of 50% individuals who prefer the most common trait, and 50% who prefer the least common, for example.  Furthermore, archaeological study of cultural transmission has typically employed "pure strategy" models, without the heterogeneity that occurs in real-world populations.  It is important for us to determine whether heterogeneous populations, represented as mixture models of population subtypes, are distinguishable given archaeological data.  If so, we should begin using mixture models in cultural transmission research.  

In this section, I first outline simulation of samples from the four models given above, and the manner in which 23 variables are measured given 9 different treatments of sampling strategy and time averaging from each simulation.  Then, I briefly describe the selection of classifier algorithm, and the metrics for evaluating classification error and thus detecting equifinality.  


## Simulated Samples of Cultural Transmission Models ##

All simulations employ the Moran dynamics, where one individual engages in a copying event at each elemental step [@moran1962statistical; @moran1958random; @aoki2011rates].  Innovations are modeled using the "infinite alleles" approximation, where every innovation has not been seen in the population previously.  Simulations were performed using the CTMixtures software package, available as open source software.\footnote{\url{https://github.com/mmadsen/ctmixtures}}  The parameters for all simulation runs are given in Table \ref{tab:parameters}.  Where there is a range given (e.g., innovation rate), the parameter is treated as a prior distribution and each simulation run is assigned a uniform random value from the range.  This ensures good coverage of the parameter space given 25,000 replicates for each of the 4 models.\footnote{The use of a good prior distribution for parameter ranges also  results in simulation data that are usable for later data fitting by approximate Bayesian inference \citep{Beaumont:2010ur, Crema:2014ef, Csillery:2010jd, Marin:2011ug}.}

\begin{table}[h]
\begin{tabular}{lc}
\hline
Parameter & Value or Interval \\ 
\hline
Innovation rate (in $\theta$ scaled units)  & $[0.1, 5.0]$   \\
Probability of conformism & $[0.05, 0.25]$ \\
Probability of anti-conformism & $[0.05, 0.25]$ \\
Sample fractions & 0.1 and 0.2 \\
Time averaging intervals (units of 100 individuals) & 10, 20, 50, 100 \\
Population size & 100 \\
Number of trait dimensions (loci) & 4 \\
Initial traits per dimension & 10 \\
\hline
\end{tabular}

\caption{Parameters for simulation runs across the four models studied.  Intervals are treated as prior distributions, and each simulation run is assigned values derived from a uniform random sample on the interval indicated.  Lists of values are all applied to every simulation run (e.g., there is both a 10\% and a 20\% sample from each simulation run.  Single values are applied to every simulation run, and represent a point prior.)}
\label{tab:parameters}
\end{table}

Simulated populations are 100 individuals in size, because most archaeological studies of cultural transmission have focused upon situations where population sizes are assumed to be small.  Additionally, equifinality should be increased in models where drift occurs due to finite-size effects.  Each simulated individual carries 4 different traits at any time, which are treated as separate loci or dimensions.  Copying involves no interaction effects between loci in this study.  The population is seeded with 10 randomly chosen traits at each Loci as the initial condition.  The evolution of each simulated population proceeds for 4 million elemental steps, which is equivalent to about 40,000 copying events on average per individual.  This value was chosen by performing simulations at 1 million time step intervals and verifying that the distribution of a key statistic (the number of traits per Loci) had stabilized.  This occurred in most cases between 2 and 3 million steps, and in all cases between 3 and 4 million, so the latter figure was chosen for creating the table of simulated samples for classification analysis.\footnote{The analysis underpinning this decision is availble in the Github repository at \url{https://github.com/mmadsen/experiment-ctmixtures/analysis/verification}.}  At the end of 4 million simulation steps, a suite of variables are measured from each of the 25,000 replicates and stored for analysis.  

## Variable Selection ##

Since equifinality is both a function of the transmission model itself, the variables we employ to measure model outcomes, and the conditions under which those variables are measured, this study examines common statistical measures of transmission over a number of sampling, time averaging, and measurement strategies.  Variation in the latter will allow us to potentially separate irreducible and reducible equifinalities.   

\begin{table}[ht]
	\begin{tabular}{lll}
		\hline
		Sampling Strategy & Time Averaging Duration \\ 
		\hline
		Population Census & 0 \\
		10\% Sample & 10 \\
		10\% Sample & 25  \\
		10\% Sample & 50 \\
		10\% Sample & 100 \\
		20\% Sample & 10  \\
		20\% Sample & 25 \\
		20\% Sample & 50 \\
		20\% Sample & 100 \\
		\hline
	\end{tabular}
	\caption{Measurement strategies, applied to every simulation run.  Time averaging duration is given in units of "generations," which are units of 100 time steps (given the population size).  100 generations thus represents 10,000 elemental time steps in the Moran simulation dynamics.}
	\label{tab:measurement-strategies}
\end{table}



The variables chosen focus upon measures of richness and diversity, trait survival over time [@kandler2013non], and the Slatkin neutrality test [@slatkin1996correction; @slatkin1994exact].  Each has been employed in the archaeological literature on identifying cultural transmission modes, or is a variant on such measures (e.g., IQV is a normalized version of other diversity measures such as entropy).  

In addition to recording the frequency of traits at each of the 4 loci, the traits at each locus were combined into a cross-tabulation which models the process of archaeological classification.  Each class represents a different combination of traits from the 4 loci, and very roughly simulates observing cultural variation through the lens of a standard paradigmatic classification [@Dunnell1971].  Each measurement (e.g., richness, diversity) was applied to each of the four loci, and to the trait configurations formed by intersection.  For the locus-centric variables, each statistic was applied to each locus separately, and the mean, minimum, and maximum of the values obtained for each locus were recorded.  I recorded the order statistics in addition to the mean value, since it is possible that minima and maxima might be a better discriminator between models than averages.  The full list of measured variables is given in Table \ref{tab:variables}.  The raw data set for this study thus consists of 900,000 measurements of the 23 variables from Table \ref{tab:variables} across the measurement treatments given in Table \ref{tab:measurement-strategies}.\footnote{All data and analyses for this study are available as part of a Github repository, although large data files are kept on Amazon S3 for long-term storage.  See \url{https://github.com/mmadsen/experiment-ctmixtures} for details.  The published analysis described here is the "equifinality-4" data set.}

\begin{table}[ht]
\begin{tabular}{lll}
\hline
Variable                                   & Measured Object & Model Variable \\ 
\hline
Trait Configuration Richness      & Trait Configuration    &  num\_trait\_configurations      \\
Slatkin Exact         & Trait Configuration   & configuration\_slatkin       \\
Shannon Entropy  & Trait Configuration &  config\_entropy \\
IQV Diversity  & Trait Configuration & config\_iqv \\
Neiman $T_f$ & Trait Configuration & config\_neiman\_tf \\
Slatkin Exact (Max of Loci)                & Loci   & slatkin\_locus\_max       \\
Slatkin Exact (Min of Loci)                & Loci    & slatkin\_locus\_min      \\
Slatkin Exact (Mean of Loci)                & Loci  & slatkin\_locus\_mean       \\
Shannon Entropy of Trait Frequencies (Min)  & Loci   & entropy\_locus\_max       \\
Shannon Entropy of Trait Frequencies (Max)  & Loci    & entropy\_locus\_min      \\
Shannon Entropy of Trait Frequencies (Mean) & Loci    & entropy\_locus\_mean      \\
IQV Diversity Index (Min)  & Loci  & iqv\_locus\_max \\
IQV Diversity Index (Max)   & Loci & iqv\_locus\_min \\
IQV Diversity Index (Mean)  & Loci & iqv\_locus\_mean \\
Trait Richness (Min) & Loci & richness\_locus\_max \\ 
Trait Richness (Max) & Loci & richness\_locus\_min \\
Trait Richness (Mean)  & Loci & richness\_locus\_mean \\
Kandler-Shennan Trait Survival (Min) & Loci & kandler\_locus\_max \\
Kandler-Shennan Trait Survival (Max) & Loci & kandler\_locus\_min \\
Kandler-Shennan Trait Survival (Mean) & Loci & kandler\_locus\_mean \\
Neiman $T_f$ (Min) & Loci & neiman\_tf\_locus\_max \\
Neiman $T_f$ (Max) & Loci & neiman\_tf\_locus\_min \\
Neiman $T_f$ (Mean) & Loci & neiman\_tf\_locus\_mean \\
\hline

\end{tabular}

\caption{Variables measured from each transmission model simulation sample.  The middle column records whether the variable is a measurement across traits in a single locus, and then summarized over loci, or whether it applies to trait configurations of all loci.  The right column records the variable name used within R statistical models, for examining the relative importance of each variable in classifying observations.}
\label{tab:variables}
\end{table}

As a final note on variable selection, in a prototype analysis for this project, I tried to include the power law exponent from a log-log transformation of trait frequency, given the important work by Bentley [-@bentley2004random] and Mesoudi and Lycett [-@Mesoudi2009]. It is not clear, however, that previous uses of this variable have been comparable to measurements we can make on archaeological assemblages.  As an example, Mesoudi and Lycett [-@Mesoudi2009] use the cumulative number of adoptions of each trait over the entire timespan of the simulation as the "frequency" used to calculate power law exponents.\footnote{I confirmed this by inspection of the source code for their simulation model, which was provided by Alex Mesoudi.}  Given the measurement strategies described in Table \ref{tab:measurement-strategies}, the number of traits present at any given time is often small, and their prevalence in a small population makes it difficult to fit a power law to the data.  Despite its importance in archaeological discussions of neutral versus biased transmission, I have omitted power law exponents from the published analysis, pending additional investigation.

## Classifier Selection and Training ##

Classifier algorithms are supervising learning models from statistics and machine learning that predict a categorical response from a mixture of discrete or continuous variables [@hastie2009elements].  The most familiar classifiers in archaeological practice are logistic regression and discriminant function analysis, but neither are competitive with contemporary "ensemble" methods which combine many classifier rules into a single prediction.  In some cases, combining predictors simply reduces the variance of prediction (e.g., bagging methods), while other ensemble classifiers can reduce bias (increasing accuracy) while also decreasing variance (e.g., random forests or some variants of boosted models).  

For our purposes, we simply need to select the best performing classifier method possible. A very general result in statistical decision theory (called, appropriately, the "No Free Lunch" theorems) guarantee that there is no single prediction model that can achieve the best result with every data set and problem [@wolpert2002supervised; @wolpert1995no; @wolpert1997no].  Thus, for practical applications, selection of near-optimal methods is sufficient.  A recent study compared 179 classifier algorithms on 121 different data sets (representing the entire UC Irvine Machine Learning Database), and found that random forests [@breiman2001random], support vector machines, and gradient boosted classifiers performed the best [@hastie2009elements].  Additionally, some ensemble methods (random forests and gradient boosted classifiers) provide information on variable importance as an integral part of the algorithm.  I simulated a small initial sample from each of the 4 cultural transmission models investigated here, and evaluated the classification accuracy of random forests against gradient boosting.\footnote{The data for this initial comparison are available in the \url{https://github.com/mmadsen/experiment-ctmixtures} repository under the experiment name "equifinality-2".}  Gradient boosted models outperformed random forests on these simulated data,  are comparable in computational costs, and were used for all results.  

Gradient boosted classification operates by repeatedly fitting a set of decision trees to the data  [@AlexeyNatekin:2013ew].  Each time classifiers are fit to the data, the error within the training data is calculated, and the next round of model fitting occurs in the direction of maximum error (or gradient) among the variables and data points [@friedman2001greedy].  This procedure iteratively improves the fit of the ensemble of classifiers.  Once a specified number of improvement rounds is reached, each classifier "votes" for the predicted class of each data point, and the majority vote for each data point is recorded as the overall model prediction.  

In addition, "boosting" is used to improve the fit of the model to difficult-to-predict data points [@freund1995boosting; @freund1999short; @schapire2012boosting].  In boosting, the errors from a previous round of fitting are used to weight each data point, with incorrectly predicted data points given higher weight (i.e., "boosted") and correct predictions downweighted.  Thus, in successive fitting rounds, boosting algorithms focus increased attention on the (hopefully dwindling) number of incorrect predictions.  The combination of boosting and ensemble methods is powerful, and such methods regularly achieve high accuracy in benchmark studies.  

In this study, I employ the standard R package (gbm) for gradient boosted classification, with the tuning parameters chosen by 5 rounds of repeated 10-fold cross-validation [@Kim:2009im; @kuhn2013applied].  The data collected from simulations were separated into a training set representing 80\% of the simulated data (balanced across the four transmission models), and the remaining 20\% for a hold-out test set.  All results reported here are from the hold-out test set, since training error overestimates accuracy.  In the present study, reporting the results from the training data set would tend to underestimate the presence of equifinality.  All classifier tuning, final model fitting, and test error evaluation was performed using Max Kuhn's superb "caret" package for R [@kuhn2008building;@kuhn2013applied].  

## Classification Error and Equifinality Assessment ##





 

# Results #




```{r load-cm, echo=FALSE, cache=FALSE, message=FALSE} 

cm_file <- load(get_data_path(suffix = "experiment-ctmixtures/equifinality-4/results", filename = "cm-merged-gbm.RData"))

# loads object cm_objects, whose keys are experiment names

```



\begin{table}
    \begin{floatrow}[2]
        \ttabbox{
            \caption{Neutral vs Balanced Biased - Sample Size:  10  Duration:  25}
            \label{tab:model-1}}
            {  
```{r xtab-pc, echo=FALSE, results='asis', cache=FALSE, message=FALSE}
xt <- xtable(cm_objects[["population_census"]][["table"]],type='latex',hline.after=c(-1,0,nrow(x)),align="|c|c|c|")
toLatex(xt, comment=FALSE, floating=FALSE)
```
            }
        
        \ttabbox{
            \caption{Neutral vs Balanced Biased - Sample Size:  10  Duration:  10}
                        \label{tab:model-1}}
            {  
```{r xtab-ta1, echo=FALSE, results='asis', cache=FALSE, message=FALSE}
xt <- xtable(cm_objects[["combined_tassize"]][["table"]],type='latex',hline.after=c(-1,0,nrow(x)),align="|c|c|c|")
toLatex(xt, comment=FALSE, floating=FALSE)
```
            }
    \end{floatrow}
    \vskip 0.5in
    \begin{floatrow}[2]
        \ttabbox{
            \caption{Neutral vs Balanced Biased - Sample Size:  10  Duration:  100}
                        \label{tab:model-1}}
            {  
```{r xtab-ta2, echo=FALSE, results='asis', cache=FALSE, message=FALSE}
xt <- xtable(cm_objects[["combined_tassize"]][["table"]],type='latex',hline.after=c(-1,0,nrow(x)),align="|c|c|c|")
toLatex(xt, comment=FALSE, floating=FALSE)
```
            }
        
        \ttabbox{
            \caption{Neutral vs Balanced Biased - Sample Size:  10  Duration:  50}
                        \label{tab:model-1}}
            {   
```{r xtab-ta3, echo=FALSE, results='asis', cache=FALSE, message=FALSE}
xt <- xtable(cm_objects[["combined_tassize"]][["table"]],type='latex',hline.after=c(-1,0,nrow(x)),align="|c|c|c|")
toLatex(xt, comment=FALSE, floating=FALSE)
```
            }
    \end{floatrow}

    \caption{Confusion matrices for four fitted GBM models}

\end{table}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim dignissim nunc, et finibus urna aliquam eget. Donec enim dolor, aliquam sed iaculis vitae, vestibulum sed justo. Curabitur fringilla, mauris quis ultrices mattis, neque libero volutpat nisi, vel mollis mi magna a felis. Phasellus a orci ut elit sodales tristique ac placerat nisi. Maecenas orci purus, ullamcorper non neque vel, imperdiet sollicitudin ante. Duis dapibus ante sed gravida imperdiet. Aenean dapibus augue nec vehicula rhoncus. Mauris ac fermentum ante, eget volutpat lectus. Nunc a est auctor, suscipit augue vel, vulputate lectus. Sed eu elit ullamcorper, interdum neque ut, varius nisi. Phasellus leo justo, mattis rutrum leo vitae, consequat auctor diam. Vivamus cursus, ligula et euismod iaculis, odio nulla ullamcorper ex, vitae cursus mi lacus at sem. Aenean dictum odio dolor, sit amet gravida sem scelerisque vitae. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Morbi.


# Discussion

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim dignissim nunc, et finibus urna aliquam eget. Donec enim dolor, aliquam sed iaculis vitae, vestibulum sed justo. Curabitur fringilla, mauris quis ultrices mattis, neque libero volutpat nisi, vel mollis mi magna a felis. Phasellus a orci ut elit sodales tristique ac placerat nisi. Maecenas orci purus, ullamcorper non neque vel, imperdiet sollicitudin ante. Duis dapibus ante sed gravida imperdiet. Aenean dapibus augue nec vehicula rhoncus. Mauris ac fermentum ante, eget volutpat lectus. Nunc a est auctor, suscipit augue vel, vulputate lectus. Sed eu elit ullamcorper, interdum neque ut, varius nisi. Phasellus leo justo, mattis rutrum leo vitae, consequat auctor diam. Vivamus cursus, ligula et euismod iaculis, odio nulla ullamcorper ex, vitae cursus mi lacus at sem. Aenean dictum odio dolor, sit amet gravida sem scelerisque vitae. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Morbi.





# Acknowledgements

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim dignissim nunc, et finibus urna aliquam eget. Donec enim dolor, aliquam sed iaculis vitae, vestibulum sed justo. Curabitur fringilla, mauris quis ultrices mattis, neque libero volutpat nisi, vel mollis mi magna a felis. Phasellus a orci ut elit sodales tristique ac placerat nisi. Maecenas orci purus, ullamcorper non neque vel, imperdiet sollicitudin ante. 

